{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "sns.set_style('darkgrid')\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)\n",
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x)) #Limiting floats output to 3 decimal points\n",
    "from subprocess import check_output\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "##display the first five rows of the train dataset.\n",
    "train.head(5)\n",
    "\n",
    "train_ID = train.loc[:,'Id']\n",
    "test_ID = test.loc[:, 'Id']\n",
    "\n",
    "train.drop(\"Id\", axis=1, inplace=True)\n",
    "test.drop(\"Id\", axis=1, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class explore_data():\n",
    "    def __init__(self, train, test):\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "    \n",
    "    def data_combine(self, target):\n",
    "        self.ntrain = self.train.shape[0]\n",
    "        self.ntest = self.test.shape[0]\n",
    "        #### Learn to automate var pulled out ####\n",
    "        self.y_train = train.loc[:, target].values\n",
    "        self.all_data = pd.concat((self.train, test)).reset_index(drop=True)\n",
    "        self.all_data.drop([var], axis=1, inplace=True)\n",
    "        print('all_data size is : {}'.format(self.all_data.shape)')\n",
    "        return self\n",
    "              \n",
    "    def missing_data(self, numdisp=40):\n",
    "        all_data_na = (self.all_data.isnull().sum() / len(self.all_data)) * 100\n",
    "        all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:numdisp]\n",
    "        missing_data = pd.DataFrame({'Missing Ratio': all_data_na})\n",
    "        print(missing_data.head(30))\n",
    "              \n",
    "        f, ax = plt.subplots(figsize=(15, 12))\n",
    "        plt.xticks(rotation='90')\n",
    "        sns.barplot(x=all_data_na.index, y=all_data_na)\n",
    "        plt.xlabel('Features', fontsize=15)\n",
    "        plt.ylabel('Percent of missing values', fontsize=15)\n",
    "        plt.title('Percent missing data by feature', fontsize=15)\n",
    "        \n",
    "        \n",
    "    def plot_single_relation(self, var, target)\n",
    "        \"\"\"\n",
    "        Use this function to plot single regression relationship, use of you know\n",
    "        correlation between var and target is high, can be used to identify easy \n",
    "        outliers in the data. \n",
    "        \"\"\"\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(x=self.train[var], y=self.train[targer])\n",
    "        plt.ylabel(targer, fontsize=13)\n",
    "        plt.xlabel(var, fontsize=13)\n",
    "        plt.show()\n",
    "    \n",
    "    def fit_norm(self, var):\n",
    "        sns.distplot(self.train[var] , fit=norm);\n",
    "        \n",
    "        # Get the fitted parameters used by the function\n",
    "        (mu, sigma) = norm.fit(self.train[var])\n",
    "        print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n",
    "        \n",
    "        #Now plot the distribution\n",
    "        plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "                    loc='best')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('SalePrice distribution')\n",
    "        \n",
    "        #Get also the QQ-plot\n",
    "        fig = plt.figure()\n",
    "        res = stats.probplot(self.train[var], plot=plt)\n",
    "        plt.show()\n",
    "    \n",
    "    def mass_correlation(self):\n",
    "        corrmat = train.corr()\n",
    "        plt.subplots(figsize=(12,9))\n",
    "        sns.heatmap(corrmat, vmax=.9, square=True)  \n",
    "              \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "class modify_data(explore_data):\n",
    "    def __init__(self, train, test):\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        \n",
    "    def remove_outliers(self):\n",
    "        train = self.train.drop(self.train[(self.train['GrLivArea']>4000) & (self.train['SalePrice']<300000)].index)\n",
    "        \n",
    "    def log1p_tranform(self, var):\n",
    "        #We use the numpy fuction log1p which  applies log(1+x) to all elements of the column\n",
    "        self.train.loc[:, var] = np.log1p(self.train[var])\n",
    "\n",
    "        #Check the new distribution \n",
    "        self.fit_norm(var)\n",
    "        return self\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
